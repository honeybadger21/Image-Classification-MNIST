{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying Image Classification Model \n",
    "\n",
    "The goal of this assignment is to create a neural network that has greater than 99% accuracy on the MNIST dataset. We can use multiple convolutional layers, different filter sizes, different number of filters, multiple max pool layers, several dense layers, regularizers, dropout layers, different batch sizes or number of epochs; whatever gets us greater than 99% accuracy on the validation set. \n",
    "\n",
    "Training and Model Saving was accomplished using Google Collab. Webpage creation and model deployment was done through Anvil. \n",
    "\n",
    ">Link to the webpage: https://msbaoptim38.anvil.app/ \n",
    "\n",
    "<b>Reference:</b>\n",
    "1. https://github.com/guptajay/Kaggle-Digit-Recognizer/blob/master/Digit_Recognizer_MNIST.ipynb \n",
    "2. https://towardsdatascience.com/going-beyond-99-mnist-handwritten-digits-recognition-cfff96337392\n",
    "\n",
    "<b>About the Dataset:</b> The <b><i>MNIST Handwritten Digits Dataset</i></b> is considered as the “Hello World” of Computer Vision. Most standard implementations of neural networks achieve an accuracy of ~(98–99) percent in correctly classifying the handwritten digits. The MNIST dataset consists of 60,000 training examples and 10,000 examples in the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3EhJfxjyKpI"
   },
   "source": [
    "<b>Importing neccessary libraries:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDsLcB8Zw4We"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Defining the Model Architechture:</b>\n",
    "\n",
    "<b>Details of the Model Used:</b> Instead of building a model from scratch, <b><i>LeNet-5 (LeCun et al., 1998. Gradient based learning applied to document recognition) convolutional neural network</i></b> was taken as the baseline standard model. It’s a simple model consisting of a convolutional layer with a max-pooling layer twice followed by two fully connected layers with a softmax output of ten classes at the end. After training for 30 epochs, the training accuracy was 99.98% & dev set accuracy was 99.05%. For a model released in 1998, the accuracy seems pretty good.\n",
    "\n",
    "However, the model suffers from both high variance and high bias problems with a test set accuracy lower than 98.74%. Let us tackle both the problems one by one. We tackle these issues as follows:\n",
    "For <b><i>Reducing Variance:</i></b> Data Augmentation, L2 Regularization, DropOut Regularization, Batch Normalization, Variable Learning Rate. For <b><i>Handling Bias: </b></i>More Layers, Deeper Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9FAhfKAw4UG"
   },
   "outputs": [],
   "source": [
    "def LeNet5v2(input_shape = (32, 32, 1), classes = 10):\n",
    "    \"\"\"\n",
    "    Implementation of a modified LeNet-5.\n",
    "    Only those layers with learnable parameters are counted in the layer numbering.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential([\n",
    "        \n",
    "    # Layer 1\n",
    "    Conv2D(filters = 32, kernel_size = 5, strides = 1, activation = 'relu', input_shape = (32,32,1), kernel_regularizer=l2(0.0005), name = 'convolution_1'),\n",
    "    \n",
    "    # Layer 2\n",
    "    Conv2D(filters = 32, kernel_size = 5, strides = 1, name = 'convolution_2', use_bias=False),\n",
    "    \n",
    "    # Layer 3    \n",
    "    BatchNormalization(name = 'batchnorm_1'),\n",
    "        \n",
    "    # -------------------------------- #  \n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(pool_size = 2, strides = 2, name = 'max_pool_1'),\n",
    "    Dropout(0.25, name = 'dropout_1'),\n",
    "    # -------------------------------- #  \n",
    "        \n",
    "    # Layer 3\n",
    "    Conv2D(filters = 64, kernel_size = 3, strides = 1, activation = 'relu', kernel_regularizer=l2(0.0005), name = 'convolution_3'),\n",
    "        \n",
    "    # Layer 4\n",
    "    Conv2D(filters = 64, kernel_size = 3, strides = 1, name = 'convolution_4', use_bias=False),\n",
    "        \n",
    "    # Layer 5\n",
    "    BatchNormalization(name = 'batchnorm_2'),\n",
    "        \n",
    "    # -------------------------------- #  \n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(pool_size = 2, strides = 2, name = 'max_pool_2'),\n",
    "    Dropout(0.25, name = 'dropout_2'),\n",
    "    Flatten(name = 'flatten'),\n",
    "    # -------------------------------- #  \n",
    "        \n",
    "    # Layer 6\n",
    "    Dense(units = 256, name = 'fully_connected_1', use_bias=False),\n",
    "        \n",
    "    # Layer 7\n",
    "    BatchNormalization(name = 'batchnorm_3'),\n",
    "    \n",
    "    # -------------------------------- #  \n",
    "    Activation(\"relu\"),\n",
    "    # -------------------------------- #  \n",
    "        \n",
    "    # Layer 8\n",
    "    Dense(units = 128, name = 'fully_connected_2', use_bias=False),\n",
    "        \n",
    "    # Layer 9\n",
    "    BatchNormalization(name = 'batchnorm_4'),\n",
    "        \n",
    "    # -------------------------------- #  \n",
    "    Activation(\"relu\"),\n",
    "    # -------------------------------- #  \n",
    "        \n",
    "    # Layer 10\n",
    "    Dense(units = 84, name = 'fully_connected_3', use_bias=False),\n",
    "        \n",
    "    # Layer 11\n",
    "    BatchNormalization(name = 'batchnorm_5'),\n",
    "        \n",
    "    # -------------------------------- #  \n",
    "    Activation(\"relu\"),\n",
    "    Dropout(0.25, name = 'dropout_3'),\n",
    "    # -------------------------------- #  \n",
    "\n",
    "    # Output\n",
    "    Dense(units = 10, activation = 'softmax', name = 'output')\n",
    "        \n",
    "    ])\n",
    "    \n",
    "    model._name = 'LeNet5v2'\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5lJ0PkbIw4Rv"
   },
   "outputs": [],
   "source": [
    "LeNet5Model = LeNet5v2(input_shape = (32, 32, 1), classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "varCAvV8w4PC"
   },
   "outputs": [],
   "source": [
    "LeNet5Model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nelIXIIJw4Mv",
    "outputId": "d8892576-0945-4eda-9c3d-df4f1e8d4f4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LeNet5v2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " convolution_1 (Conv2D)      (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " convolution_2 (Conv2D)      (None, 24, 24, 32)        25600     \n",
      "                                                                 \n",
      " batchnorm_1 (BatchNormaliza  (None, 24, 24, 32)       128       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " activation (Activation)     (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " max_pool_1 (MaxPooling2D)   (None, 12, 12, 32)        0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 12, 12, 32)        0         \n",
      "                                                                 \n",
      " convolution_3 (Conv2D)      (None, 10, 10, 64)        18496     \n",
      "                                                                 \n",
      " convolution_4 (Conv2D)      (None, 8, 8, 64)          36864     \n",
      "                                                                 \n",
      " batchnorm_2 (BatchNormaliza  (None, 8, 8, 64)         256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " max_pool_2 (MaxPooling2D)   (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " fully_connected_1 (Dense)   (None, 256)               262144    \n",
      "                                                                 \n",
      " batchnorm_3 (BatchNormaliza  (None, 256)              1024      \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " fully_connected_2 (Dense)   (None, 128)               32768     \n",
      "                                                                 \n",
      " batchnorm_4 (BatchNormaliza  (None, 128)              512       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " fully_connected_3 (Dense)   (None, 84)                10752     \n",
      "                                                                 \n",
      " batchnorm_5 (BatchNormaliza  (None, 84)               336       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 84)                0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 390,562\n",
      "Trainable params: 389,434\n",
      "Non-trainable params: 1,128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LeNet5Model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2A5suShAFq81"
   },
   "source": [
    ">We have about 40k parameters to train. \n",
    "\n",
    "To summarise, we are using two convolutional layers, followed by a pooling layer twice (once with 32 filters and 64 filters respectively) and three fully connected layers with a softmax unit in the end with 10 classes. Batch Normalization, L2 Regularization and Dropouts are done in-between the layers. \n",
    "\n",
    "<b>Loading the Dataset:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "_1-51y1Xw4KH",
    "outputId": "e9c5172a-35ad-40fa-f37c-6f83fee7eec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n",
      "Size of Dataset:  60000\n",
      "Size of Cross Validation Set:  3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5fa23ebd60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "Y = y_train\n",
    "X = x_train\n",
    "\n",
    "test = x_test\n",
    "\n",
    "X = X.reshape(-1,28,28,1)\n",
    "test = test.reshape(-1,28,28,1)\n",
    "print(\"Size of Dataset: \" , len(X))\n",
    "\n",
    "cross_validation_size = int(len(X)*0.05)\n",
    "print(\"Size of Cross Validation Set: \" , cross_validation_size)\n",
    "\n",
    "random_seed = 2\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = cross_validation_size, random_state=random_seed)\n",
    "\n",
    "X_test = test\n",
    "plt.imshow(X_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Image Pre-Processing Steps:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsUO355Uw4H4"
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Padding the images by 2 pixels since in the paper input images were 32x32\n",
    "\n",
    "X_train = np.pad(X_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_val = np.pad(X_val, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_test = np.pad(X_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "\n",
    "# Standardization\n",
    "\n",
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)\n",
    "X_train = (X_train - mean_px)/(std_px)\n",
    "\n",
    "mean_px = X_val.mean().astype(np.float32)\n",
    "std_px = X_val.std().astype(np.float32)\n",
    "X_val = (X_val - mean_px)/(std_px)\n",
    "\n",
    "mean_px = X_test.mean().astype(np.float32)\n",
    "std_px = X_test.std().astype(np.float32)\n",
    "X_test = (X_test - mean_px)/(std_px)\n",
    "\n",
    "# One-hot encoding the labels\n",
    "\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "Y_val = to_categorical(Y_val, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQ5wm8Dpxywo"
   },
   "outputs": [],
   "source": [
    "# By using the image generator, we are not generating new data. We are only replacing the exisiting images. \n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center = False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center = False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization = False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization = False,  # divide each input by its std\n",
    "        zca_whitening = False,  # apply ZCA whitening\n",
    "        rotation_range = 10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range = 0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range = 0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = False,  # randomly flip images\n",
    "        vertical_flip = False)  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OXDViDbjxyzB"
   },
   "outputs": [],
   "source": [
    "variable_learning_rate = ReduceLROnPlateau(monitor='val_loss', factor = 0.2, patience = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ygipgNjxy1f"
   },
   "outputs": [],
   "source": [
    "#history = LeNet5Model.fit(X_train, Y_train, epochs = 30, batch_size = 64, callbacks = [variable_learning_rate], validation_data = (X_val,Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Training the Model:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KwuhCesdF3zc",
    "outputId": "08638472-99ca-43f8-fb56-5fcc86d0577a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "891/891 [==============================] - 17s 9ms/step - loss: 0.2171 - accuracy: 0.9436 - val_loss: 0.0740 - val_accuracy: 0.9823 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "891/891 [==============================] - 8s 8ms/step - loss: 0.0859 - accuracy: 0.9799 - val_loss: 0.0519 - val_accuracy: 0.9893 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0659 - accuracy: 0.9847 - val_loss: 0.0424 - val_accuracy: 0.9890 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0572 - accuracy: 0.9865 - val_loss: 0.0451 - val_accuracy: 0.9913 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0516 - accuracy: 0.9871 - val_loss: 0.0639 - val_accuracy: 0.9820 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0330 - accuracy: 0.9925 - val_loss: 0.0304 - val_accuracy: 0.9947 - lr: 2.0000e-04\n",
      "Epoch 7/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0285 - accuracy: 0.9937 - val_loss: 0.0271 - val_accuracy: 0.9950 - lr: 2.0000e-04\n",
      "Epoch 8/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0246 - accuracy: 0.9948 - val_loss: 0.0285 - val_accuracy: 0.9953 - lr: 2.0000e-04\n",
      "Epoch 9/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0241 - accuracy: 0.9946 - val_loss: 0.0260 - val_accuracy: 0.9957 - lr: 2.0000e-04\n",
      "Epoch 10/30\n",
      "891/891 [==============================] - 8s 9ms/step - loss: 0.0220 - accuracy: 0.9950 - val_loss: 0.0262 - val_accuracy: 0.9950 - lr: 2.0000e-04\n",
      "Epoch 11/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0199 - accuracy: 0.9954 - val_loss: 0.0268 - val_accuracy: 0.9950 - lr: 2.0000e-04\n",
      "Epoch 12/30\n",
      "891/891 [==============================] - 8s 8ms/step - loss: 0.0185 - accuracy: 0.9960 - val_loss: 0.0244 - val_accuracy: 0.9953 - lr: 4.0000e-05\n",
      "Epoch 13/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0168 - accuracy: 0.9964 - val_loss: 0.0246 - val_accuracy: 0.9953 - lr: 4.0000e-05\n",
      "Epoch 14/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0145 - accuracy: 0.9971 - val_loss: 0.0242 - val_accuracy: 0.9960 - lr: 4.0000e-05\n",
      "Epoch 15/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0149 - accuracy: 0.9970 - val_loss: 0.0233 - val_accuracy: 0.9967 - lr: 4.0000e-05\n",
      "Epoch 16/30\n",
      "891/891 [==============================] - 8s 8ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.0244 - val_accuracy: 0.9950 - lr: 4.0000e-05\n",
      "Epoch 17/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.0248 - val_accuracy: 0.9957 - lr: 4.0000e-05\n",
      "Epoch 18/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0128 - accuracy: 0.9976 - val_loss: 0.0244 - val_accuracy: 0.9960 - lr: 8.0000e-06\n",
      "Epoch 19/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 0.0243 - val_accuracy: 0.9960 - lr: 8.0000e-06\n",
      "Epoch 20/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.0239 - val_accuracy: 0.9960 - lr: 1.6000e-06\n",
      "Epoch 21/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0132 - accuracy: 0.9974 - val_loss: 0.0239 - val_accuracy: 0.9960 - lr: 1.6000e-06\n",
      "Epoch 22/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 0.0241 - val_accuracy: 0.9960 - lr: 3.2000e-07\n",
      "Epoch 23/30\n",
      "891/891 [==============================] - 8s 9ms/step - loss: 0.0130 - accuracy: 0.9975 - val_loss: 0.0243 - val_accuracy: 0.9960 - lr: 3.2000e-07\n",
      "Epoch 24/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0129 - accuracy: 0.9972 - val_loss: 0.0239 - val_accuracy: 0.9957 - lr: 6.4000e-08\n",
      "Epoch 25/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0136 - accuracy: 0.9973 - val_loss: 0.0241 - val_accuracy: 0.9957 - lr: 6.4000e-08\n",
      "Epoch 26/30\n",
      "891/891 [==============================] - 8s 9ms/step - loss: 0.0135 - accuracy: 0.9972 - val_loss: 0.0241 - val_accuracy: 0.9957 - lr: 1.2800e-08\n",
      "Epoch 27/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0128 - accuracy: 0.9974 - val_loss: 0.0241 - val_accuracy: 0.9957 - lr: 1.2800e-08\n",
      "Epoch 28/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 0.0241 - val_accuracy: 0.9957 - lr: 2.5600e-09\n",
      "Epoch 29/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0128 - accuracy: 0.9976 - val_loss: 0.0241 - val_accuracy: 0.9957 - lr: 2.5600e-09\n",
      "Epoch 30/30\n",
      "891/891 [==============================] - 7s 8ms/step - loss: 0.0131 - accuracy: 0.9975 - val_loss: 0.0238 - val_accuracy: 0.9957 - lr: 5.1200e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5fa23c0550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LeNet5Model.fit(X_train, Y_train, epochs = 30, batch_size = 64, callbacks = [variable_learning_rate], validation_data = (X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "nvYWevEJxy31",
    "outputId": "c72a853a-8ac9-444f-c7b2-9def829675f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Saving the trained model to Google Drive:</b> \\\n",
    "We don't want our model to run on anvil. Our code on Google Collab serves as the backend and we wish that the training and prediction of the model occurs here itself. The anvil webpage is just meant to serve as a tool to use the model at the backend in a user-friendly fashion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WqSQakhziDNE",
    "outputId": "15cce006-468b-46c6-afb7-09f597d8446e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbQPzGn_iDPv",
    "outputId": "42203dae-afef-4bd6-9fb8-0533b0935ef4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "LeNet5Model.save('model01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Loading the Saved Model & just testing it around:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BLK9G2Q4k7f"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/content/model01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sv6QCqij0JMO",
    "outputId": "3ad9728f-2f94-457d-a275-4bc539978243"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.4723054e-08, 8.8056220e-07, 5.5330293e-07, ..., 9.9999416e-01,\n",
       "        2.9794004e-08, 2.8615477e-06],\n",
       "       [9.4641806e-08, 5.9463318e-06, 9.9998832e-01, ..., 5.6362472e-07,\n",
       "        4.2333238e-07, 3.7168260e-07],\n",
       "       [1.3393417e-07, 9.9999404e-01, 1.2596232e-06, ..., 2.3351106e-06,\n",
       "        3.3310326e-07, 2.4445984e-07],\n",
       "       ...,\n",
       "       [3.4806529e-08, 1.7250204e-07, 1.8377462e-09, ..., 9.1992405e-08,\n",
       "        7.7744198e-07, 1.4016234e-06],\n",
       "       [6.9633309e-08, 2.6005976e-08, 1.4608998e-08, ..., 7.5380648e-08,\n",
       "        6.4661281e-06, 4.4630582e-07],\n",
       "       [4.7279441e-06, 3.3468289e-06, 1.4659629e-05, ..., 1.2261165e-07,\n",
       "        1.1030751e-05, 1.5011559e-06]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jFiAWG9n1dvV",
    "outputId": "8f8e9e2a-1b92-4bb8-9a38-b6ccc14a284e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_probs2 = model.predict(X_test)\n",
    "pred = np.argmax(pred_probs2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9DaUkaE0JO0",
    "outputId": "af2e32db-e27c-4f4d-d43d-223cbc009044"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H0XuEgB_1su3",
    "outputId": "33c06a42-6775-4534-f220-5920849d650e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 194ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.9986854e-01, 5.3302804e-04, 6.2807341e-04, 4.1419157e-04,\n",
       "        3.0202964e-02, 7.8012858e-04, 1.1334107e-03, 4.2225185e-04,\n",
       "        7.6531577e-01, 7.0157356e-04]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa = np.array([[0]*28]*28)\n",
    "\n",
    "fa = fa.reshape(-1,28,28,1)\n",
    "fa = np.array(fa)\n",
    "fa = np.pad(fa, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "# X_test = (X_test - mean_px)/(std_px)\n",
    "\n",
    "def tf(arr):\n",
    "    return model.predict([arr])\n",
    "  \n",
    "    pass\n",
    "\n",
    "tf(fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xpI9xrZD1sya",
    "outputId": "92fb6e4c-a269-4972-e11c-4c62f31848c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(tf(fa), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q70pwiEd1s1K"
   },
   "source": [
    "<b>Deploying the Model to Anvil:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "KfJT-ha5k3ag",
    "outputId": "e5de9465-8e71-4825-aba9-c7e5560b90bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting anvil-uplink\n",
      "  Downloading anvil_uplink-0.4.2-py2.py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting argparse\n",
      "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from anvil-uplink) (0.16.0)\n",
      "Collecting ws4py\n",
      "  Downloading ws4py-0.5.1.tar.gz (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from anvil-uplink) (1.15.0)\n",
      "Building wheels for collected packages: ws4py\n",
      "  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for ws4py: filename=ws4py-0.5.1-py3-none-any.whl size=45229 sha256=a902de8bcc79be534422628610ce63920adb1e5f3a1c9886335004196473c10b\n",
      "  Stored in directory: /root/.cache/pip/wheels/ea/f9/a1/34e2943cce3cf7daca304bfc35e91280694ced9194a487ce2f\n",
      "Successfully built ws4py\n",
      "Installing collected packages: ws4py, argparse, anvil-uplink\n",
      "Successfully installed anvil-uplink-0.4.2 argparse-1.4.0 ws4py-0.5.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "argparse",
         "google"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pip install anvil-uplink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aEvs5jf9k3c4",
    "outputId": "243ce3db-c7c3-4e31-aaca-4522f7b46485"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Connected to \"Development\" as SERVER\n"
     ]
    }
   ],
   "source": [
    "import anvil.server\n",
    "anvil.server.connect(\"server_2ZFMOGCN4XGVNPHZJEAZKEQU-27FWMJWBQ7YMXCNP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hJ2EkZpk3fm"
   },
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def test_func(fetch_array):\n",
    "  \n",
    "  #fetch_array = fetch_array.to_numpy()\n",
    "  #fetch_array = tf.reshape(fetch_array,(1,28,28,1))\n",
    "  fetch_array = np.array(fetch_array).reshape(-1,28,28,1)\n",
    "  #fetch_array = np.array(fetch_array)\n",
    "  fetch_array = np.pad(fetch_array, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "\n",
    "  # return_value = np.argmax(LeNet5Model.predict(np.expand_dims(np.expand_dims(fetch_array, axis=0), axis=3)), axis=1)[0]\n",
    "  return_val = np.argmax(model.predict(fetch_array), axis = 1)\n",
    "  return return_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WMMtw48I9qTj",
    "outputId": "07d4f005-875c-45a5-dc55-482c1577a3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n"
     ]
    }
   ],
   "source": [
    "anvil.server.wait_forever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDKa5KhS_k98"
   },
   "source": [
    "<b>The End.</b>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
